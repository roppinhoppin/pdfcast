## Mathematical Statements:

**Equation of Motion (EoM) for DNNs:**  
We modify the gradient flow (GF) to include a counter term that cancels discretization error:
$$
\pmb{\dot{\theta}}(t)=-\pmb{g}(\pmb{\theta}(t))-\eta\pmb{\xi}(\pmb{\theta}(t)),
$$
where $\pmb{\theta}(t) \in \mathbb{R}^{d}$ is the vectorized weight parameters of a DNN at time $t \in \mathbb{R}$, $d \in \mathbb{N}$ is the dimension of the weight, and $\dot{\pmb\theta}(t)$ denotes $d\pmb{\theta}(t)/dt$. Gradient $\pmb{g}(\pmb{\theta}(t))$ is defined as $\nabla f(\pmb{\theta}(t))+\lambda\pmb{\theta}(t)$.

**Theorem 3.1 (Recursive formula for discretization error):**  
Discretization error $e_{k}$ satisfies:
$$
{e_{k+1}-e_{k}=-\eta\big(g(\theta(k\eta))-g(\theta(k\eta)-e_{k})\big)+\Lambda(\theta(k\eta))},
$$
where $\Lambda(\pmb{\theta}(k\eta)):=\eta^{2}\int_{0}^{1}d s\,\ddot{\pmb{\theta}}(\eta(k+s))(1-s)-\eta^{2}\pmb{\xi}(\pmb{\theta}(k\eta)).$

**Theorem 3.2 (Leading order of discretization error):**  
Suppose $\mathbf{\Lambda}(\theta(k\eta))=O(\eta^{\gamma})$ and $e_{0}=O(\eta^{\gamma})$ for some $\gamma>0$. Then $e_{k}=O(\eta^{\gamma})$ and $-\eta(\pmb{g}(\pmb{\theta}(k\eta))-\pmb{g}(\pmb{\theta}(k\eta)-e_{k}))=O(\eta^{\gamma+1})$. Therefore, the leading order of discretization error is:
$$
\Lambda(\theta(k\eta))=O(\eta^{\gamma}) \iff \int_{0}^{1}d s\,\ddot{\theta}(\eta(k+s))(1-s)-\xi(\theta(k\eta))=O(\eta^{\gamma-2}).
$$

**Theorem 3.3 (Solution of Equation for Counter Term $\xi$):**  
The solution to the functional integral equation of form is given by:
$$
\xi_{\alpha}(\pmb{\theta}) = \tilde{\xi}_{\alpha}(\pmb{\theta}):=\sum_{i=2}^{\alpha+2}\sum_{k_{1}+\cdots+k_{i}=\alpha-i+2}\frac{(-1)^{i}}{i!}D_{k_{1}}\cdots D_{k_{i-1}}\Xi_{k_{i}}
$$
for $\alpha=0,1,2,\ldots$, with $D_{\alpha}$ as differential operators (Lie derivatives) and $$\Xi_{\alpha}(\pmb{\theta}) = \tilde{\xi}_{\alpha-1}(\pmb{\theta})'$$ for $\alpha=1,2,\ldots,$ with $\Xi_{0}(\theta) = g(\theta)$.